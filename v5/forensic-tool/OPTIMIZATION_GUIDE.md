# æ€§èƒ½ä¼˜åŒ–å¿«é€Ÿå®æ–½æŒ‡å—

## ğŸš€ ç«‹å³å¯å®æ–½çš„ä¼˜åŒ–ï¼ˆ1-2 å¤©ï¼Œæå‡ 50-500 å€ï¼‰

### ç¬¬ä¸€æ­¥ï¼šå®‰è£…çœŸå® Redisï¼ˆ30 åˆ†é’Ÿï¼‰

#### Linux / macOS
```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install redis-server

# macOS
brew install redis

# å¯åŠ¨ Redis
sudo service redis-server start  # Linux
brew services start redis         # macOS

# æµ‹è¯• Redis
redis-cli ping
# åº”è¯¥è¿”å›: PONG
```

#### Windows
```cmd
# ä¸‹è½½ Redis for Windows
# https://github.com/microsoftarchive/redis/releases

# è§£å‹å¹¶å¯åŠ¨
redis-server.exe
```

---

### ç¬¬äºŒæ­¥ï¼šä¿®æ”¹ä»£ç ä½¿ç”¨çœŸå® Redisï¼ˆ15 åˆ†é’Ÿï¼‰

åˆ›å»º `main_optimized.py`ï¼š

```python
import redis

# æ›¿æ¢è¿™éƒ¨åˆ†ä»£ç 
# åŸä»£ç ï¼ˆç¬¬ 11-17 è¡Œï¼‰ï¼š
# r = fakeredis.FakeRedis(decode_responses=False)
# try:
#     r.config_set("maxmemory", "10GB")
#     r.config_set("maxmemory-policy", "volatile-lru")
# except Exception:
#     pass

# æ–°ä»£ç ï¼š
r = redis.Redis(
    host='localhost',
    port=6379,
    db=0,
    decode_responses=False,
    max_connections=50,
    socket_timeout=5,
    socket_connect_timeout=5
)

try:
    r.config_set('maxmemory', '4gb')
    r.config_set('maxmemory-policy', 'allkeys-lru')
    r.config_set('timeout', 300)
except Exception as e:
    print(f"è­¦å‘Š: Redis é…ç½®å¤±è´¥: {e}")

# æµ‹è¯•è¿æ¥
try:
    r.ping()
    print("âœ“ Redis è¿æ¥æˆåŠŸ")
except Exception as e:
    print(f"âœ— Redis è¿æ¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿ Redis æœåŠ¡å·²å¯åŠ¨")
```

---

### ç¬¬ä¸‰æ­¥ï¼šæ·»åŠ æ•°æ®åº“ç´¢å¼•ï¼ˆ10 åˆ†é’Ÿï¼‰

åœ¨ `main_optimized.py` ä¸­ä¿®æ”¹æ•°æ®åº“åˆå§‹åŒ–éƒ¨åˆ†ï¼š

```python
# åœ¨ conn.commit() ä¹‹åæ·»åŠ ï¼ˆç¬¬ 49 è¡Œåï¼‰

# åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
indexes = [
    'CREATE INDEX IF NOT EXISTS idx_package_name ON file_data(package_name)',
    'CREATE INDEX IF NOT EXISTS idx_file_path ON file_data(file_path)',
    'CREATE INDEX IF NOT EXISTS idx_category ON file_data(category)',
    'CREATE INDEX IF NOT EXISTS idx_create_time ON file_data(create_time)'
]

for idx_sql in indexes:
    try:
        cursor.execute(idx_sql)
        print(f"âœ“ ç´¢å¼•åˆ›å»ºæˆåŠŸ: {idx_sql.split('ON')[1].strip()}")
    except Exception as e:
        print(f"âœ— ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")

conn.commit()

# ä¼˜åŒ– SQLite æ€§èƒ½
sqlite_optimizations = [
    'PRAGMA journal_mode=WAL',      # WAL æ¨¡å¼ï¼Œæé«˜å¹¶å‘
    'PRAGMA synchronous=NORMAL',    # é™ä½åŒæ­¥çº§åˆ«
    'PRAGMA cache_size=-64000',      # 64MB ç¼“å­˜
    'PRAGMA temp_store=MEMORY',      # ä¸´æ—¶è¡¨åœ¨å†…å­˜
    'PRAGMA mmap_size=268435456',    # 256MB å†…å­˜æ˜ å°„
    'PRAGMA page_size=4096',         # é¡µé¢å¤§å°
]

for opt in sqlite_optimizations:
    try:
        cursor.execute(opt)
        print(f"âœ“ SQLite ä¼˜åŒ–: {opt}")
    except Exception as e:
        print(f"âœ— SQLite ä¼˜åŒ–å¤±è´¥: {e}")

conn.commit()
```

---

### ç¬¬å››æ­¥ï¼šæµ‹è¯•æ€§èƒ½æå‡ï¼ˆ5 åˆ†é’Ÿï¼‰

åˆ›å»º `test_performance.py`ï¼š

```python
import requests
import time
import json

def test_api_performance():
    print("=" * 60)
    print("æ€§èƒ½æµ‹è¯•")
    print("=" * 60)

    # æµ‹è¯• 1: åŒ…åæŸ¥è¯¢
    print("\næµ‹è¯• 1: è·å–åŒ…ååˆ—è¡¨")
    start = time.time()
    resp = requests.get('http://localhost:8000/packages')
    elapsed = (time.time() - start) * 1000
    print(f"å“åº”æ—¶é—´: {elapsed:.2f} ms")
    print(f"åŒ…åæ•°é‡: {len(resp.json().get('data', []))}")

    # æµ‹è¯• 2: å…³é”®è¯æŸ¥è¯¢
    print("\næµ‹è¯• 2: å…³é”®è¯æŸ¥è¯¢ (SQLite)")
    start = time.time()
    resp = requests.post(
        'http://localhost:8000/query',
        json={'keyword': 'test', 'source': 'sqlite'}
    )
    elapsed = (time.time() - start) * 1000
    result = resp.json()
    print(f"å“åº”æ—¶é—´: {elapsed:.2f} ms")
    print(f"åŒ¹é…æ•°é‡: {result.get('count', 0)}")

    # æµ‹è¯• 3: åŒ…åè·¯å¾„æŸ¥è¯¢
    print("\næµ‹è¯• 3: åŒ…åè·¯å¾„æŸ¥è¯¢")
    packages = requests.get('http://localhost:8000/packages').json().get('data', [])
    if packages:
        start = time.time()
        resp = requests.get(
            f'http://localhost:8000/package_paths?package_name={packages[0]}'
        )
        elapsed = (time.time() - start) * 1000
        result = resp.json()
        print(f"å“åº”æ—¶é—´: {elapsed:.2f} ms")
        print(f"æ–‡ä»¶æ•°é‡: {len(result.get('paths', []))}")

    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 60)

if __name__ == "__main__":
    test_api_performance()
```

è¿è¡Œæµ‹è¯•ï¼š
```bash
python3 test_performance.py
```

---

## ğŸ“Š é¢„æœŸæ€§èƒ½æå‡

### ä¼˜åŒ–å‰ vs ä¼˜åŒ–å

| æ“ä½œ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å€æ•° |
|------|--------|--------|----------|
| è·å–åŒ…ååˆ—è¡¨ | 50-200 ms | 1-10 ms | 10-200x |
| å…³é”®è¯æŸ¥è¯¢ | 20-100 ms | 0.5-5 ms | 10-200x |
| åŒ…åè·¯å¾„æŸ¥è¯¢ | 10-50 ms | 0.5-5 ms | 10-100x |
| æ‰«æ 1000 æ–‡ä»¶ | 1-5 ç§’ | 0.5-2 ç§’ | 2-10x |
| å¹¶å‘å¤„ç† | 100 QPS | 500-2000 QPS | 5-20x |

---

## ğŸ”§ è¿›é˜¶ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

### 5.1 æ‰¹é‡æ’å…¥ä¼˜åŒ–

ä¿®æ”¹ `scan_and_extract` å‡½æ•°ä¸­çš„æ‰¹é‡æ’å…¥éƒ¨åˆ†ï¼š

```python
# ä¼˜åŒ–æ‰¹é‡æ’å…¥å¤§å°
BATCH_SIZE = 500  # ä» 100 å¢åŠ åˆ° 500

# åœ¨æ‰¹å¤„ç†æ—¶ä½¿ç”¨äº‹åŠ¡
def batch_insert(cursor, conn, batch_data):
    """æ‰¹é‡æ’å…¥æ•°æ®"""
    if not batch_data:
        return

    try:
        # ä½¿ç”¨äº‹åŠ¡
        cursor.execute('BEGIN TRANSACTION')
        cursor.executemany('''
        INSERT OR REPLACE INTO file_data (file_path, package_name, content, category)
        VALUES (?, ?, ?, ?)
        ''', batch_data)
        conn.commit()
        print(f"âœ“ æ‰¹é‡æ’å…¥ {len(batch_data)} æ¡è®°å½•")
    except Exception as e:
        conn.rollback()
        print(f"âœ— æ‰¹é‡æ’å…¥å¤±è´¥: {e}")
```

---

### 5.2 è¿æ¥æ± ä¼˜åŒ–

åˆ›å»º `db_pool.py`ï¼š

```python
import sqlite3
from contextlib import contextmanager
from threading import Lock

class DatabasePool:
    """SQLite è¿æ¥æ± """

    def __init__(self, db_path: str, pool_size: int = 10):
        self.db_path = db_path
        self.pool_size = pool_size
        self.connections = []
        self.lock = Lock()
        self._init_pool()

    def _init_pool(self):
        """åˆå§‹åŒ–è¿æ¥æ± """
        print(f"åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ±  ({self.pool_size} ä¸ªè¿æ¥)...")
        for i in range(self.pool_size):
            conn = sqlite3.connect(
                self.db_path,
                check_same_thread=False,
                isolation_level=None,  # è‡ªåŠ¨æäº¤
                timeout=30
            )

            # åº”ç”¨æ€§èƒ½ä¼˜åŒ–
            conn.execute('PRAGMA journal_mode=WAL')
            conn.execute('PRAGMA synchronous=NORMAL')
            conn.execute('PRAGMA cache_size=-64000')
            conn.execute('PRAGMA temp_store=MEMORY')
            conn.execute('PRAGMA mmap_size=268435456')

            self.connections.append(conn)
            print(f"âœ“ è¿æ¥ {i+1}/{self.pool_size} å·²åˆ›å»º")

    @contextmanager
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        with self.lock:
            conn = self.connections.pop()
        try:
            yield conn
        finally:
            with self.lock:
                self.connections.append(conn)

    def close_all(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        for conn in self.connections:
            conn.close()
        self.connections.clear()
        print("âœ“ æ‰€æœ‰æ•°æ®åº“è¿æ¥å·²å…³é—­")

# ä½¿ç”¨ç¤ºä¾‹
# db_pool = DatabasePool('forensic.db', pool_size=10)
#
# with db_pool.get_connection() as conn:
#     cursor = conn.cursor()
#     cursor.execute('SELECT ...')
#     results = cursor.fetchall()
```

åœ¨ `main_optimized.py` ä¸­ä½¿ç”¨ï¼š

```python
from db_pool import DatabasePool

# æ›¿æ¢å•ä¸€è¿æ¥
# åŸä»£ç ï¼š
# conn = sqlite3.connect("forensic.db", check_same_thread=False)
# cursor = conn.cursor()

# æ–°ä»£ç ï¼š
db_pool = DatabasePool('forensic.db', pool_size=10)

# åœ¨éœ€è¦æŸ¥è¯¢çš„åœ°æ–¹ä½¿ç”¨
with db_pool.get_connection() as conn:
    cursor = conn.cursor()
    cursor.execute('SELECT DISTINCT package_name FROM file_data WHERE package_name != "æœªçŸ¥åŒ…å"')
    packages = [row[0] for row in cursor.fetchall()]
```

---

## ğŸ“ å®æ–½æ£€æŸ¥æ¸…å•

### å¿…åšé¡¹ï¼ˆç«‹å³å®æ–½ï¼‰
- [ ] å®‰è£… Redis æœåŠ¡
- [ ] æµ‹è¯• Redis è¿æ¥
- [ ] ä¿®æ”¹ä»£ç ä½¿ç”¨çœŸå® Redis
- [ ] æ·»åŠ æ•°æ®åº“ç´¢å¼•
- [ ] ä¼˜åŒ– SQLite é…ç½®
- [ ] æµ‹è¯•æ€§èƒ½æå‡

### æ¨èé¡¹ï¼ˆ1-2 å‘¨å†…ï¼‰
- [ ] å®æ–½å¤šçº¿ç¨‹æ‰«æ
- [ ] ä¼˜åŒ–æ‰¹é‡æ’å…¥
- [ ] ä½¿ç”¨è¿æ¥æ± 
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§

### å¯é€‰é¡¹ï¼ˆé•¿æœŸè§„åˆ’ï¼‰
- [ ] è¿ç§»åˆ° PostgreSQL/MySQL
- [ ] é‡æ„ä¸º Electron åº”ç”¨
- [ ] æ·»åŠ å¤šå±‚ç¼“å­˜
- [ ] UI å¼‚æ­¥åŒ–

---

## ğŸ› æ•…éšœæ’æŸ¥

### Redis è¿æ¥å¤±è´¥

**é”™è¯¯**: `ConnectionError: Error 111 connecting to localhost:6379`

**è§£å†³**:
```bash
# æ£€æŸ¥ Redis æ˜¯å¦è¿è¡Œ
ps aux | grep redis

# å¯åŠ¨ Redis
sudo service redis-server start  # Linux
brew services start redis         # macOS

# æµ‹è¯•è¿æ¥
redis-cli ping
```

### ç´¢å¼•åˆ›å»ºå¤±è´¥

**é”™è¯¯**: `database is locked`

**è§£å†³**:
```bash
# åœæ­¢æ‰€æœ‰ä½¿ç”¨æ•°æ®åº“çš„è¿›ç¨‹
pkill -f python3 main.py

# åˆ é™¤ WAL æ–‡ä»¶
rm forensic.db-wal forensic.db-shm

# é‡æ–°å¯åŠ¨
python3 main.py
```

### æ€§èƒ½æ²¡æœ‰æå‡

**æ£€æŸ¥**:
```bash
# 1. ç¡®è®¤ä½¿ç”¨äº†çœŸå® Redis
python3 -c "import redis; r = redis.Redis(); print('Real Redis' if type(r).__name__ == 'Redis' else 'Fake Redis')"

# 2. æ£€æŸ¥ç´¢å¼•æ˜¯å¦åˆ›å»º
sqlite3 forensic.db "SELECT name FROM sqlite_master WHERE type='index'"

# 3. æŸ¥çœ‹æ€§èƒ½æ—¥å¿—
tail -f /tmp/api.log
```

---

## ğŸ“š ç›¸å…³èµ„æº

- **Redis æ–‡æ¡£**: https://redis.io/documentation
- **SQLite ä¼˜åŒ–**: https://www.sqlite.org/optoverview.html
- **FastAPI æ–‡æ¡£**: https://fastapi.tiangolo.com/
- **Python æ€§èƒ½ä¼˜åŒ–**: https://wiki.python.org/moin/PythonSpeed

---

## ğŸ’¡ ä¸‹ä¸€æ­¥

å®Œæˆç´§æ€¥ä¼˜åŒ–åï¼Œæ‚¨å¯ä»¥è€ƒè™‘ï¼š

1. **ç›‘æ§æ€§èƒ½**: æ·»åŠ æ—¥å¿—å’Œæ€§èƒ½æŒ‡æ ‡
2. **å‹åŠ›æµ‹è¯•**: ä½¿ç”¨å·¥å…·æµ‹è¯•å¹¶å‘èƒ½åŠ›
3. **ç”¨æˆ·åé¦ˆ**: æ”¶é›†å®é™…ä½¿ç”¨ä¸­çš„æ€§èƒ½é—®é¢˜
4. **æŒç»­ä¼˜åŒ–**: æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ä¼˜åŒ–ç­–ç•¥

**é¢„æœŸæ•ˆæœ**: å®Œæˆç´§æ€¥ä¼˜åŒ–åï¼Œæ‚¨çš„ç¨‹åºæ€§èƒ½å°†æå‡ **50-500 å€**ï¼Œæ¥è¿‘å•†ä¸šè½¯ä»¶æ°´å¹³ï¼
